{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "model_df = pd.read_csv(\"../csv/vdi_entailment_scores_with_cosine_similarity_chunk_size_256_all-MiniLM-L6-v2.csv\")\n",
    "model_df = model_df.sort_values(by=['company', 'year'])\n",
    "\n",
    "manual_df = pd.read_csv(\"../csv/vdi_scores_manual.csv\")\n",
    "manual_df = manual_df.sort_values(by=['company', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 70):\n",
    "    cols = [f'entailment_q{i}_{j}' for j in range(1, 11)]\n",
    "    model_df[f'entailment_q{i}'] = model_df[cols].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.merge(\n",
    "    manual_df,\n",
    "    model_df,\n",
    "    on=['company', 'year'],\n",
    "    how='inner'\n",
    ").sort_values(by=['company', 'year'])\n",
    "cols = ['company', 'year', 'vdi_score_unscaled']\n",
    "for i in range(1, 70):\n",
    "    cols.append(f'entailment_q{i}')\n",
    "new_df = new_df.loc[:, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [f'entailment_q{i}' for i in range(1, 70)]\n",
    "X = new_df.loc[:, cols].to_numpy()\n",
    "y = new_df.loc[:, \"vdi_score_unscaled\"].to_numpy()\n",
    "\n",
    "X_train = np.delete(X, np.s_[15:17], axis=0)\n",
    "X_test = X[15:17, :]\n",
    "y_train = np.delete(y, np.s_[15:17])\n",
    "y_test = y[15:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = scaler.fit_transform(y_train.reshape(-1, 1))\n",
    "# y_test = scaler.transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_with_intercept = np.hstack((np.ones((X_train.shape[0], 1)), X_train))\n",
    "\n",
    "coefficients = np.linalg.inv(X_train_with_intercept.T @ X_train_with_intercept) @ X_train_with_intercept.T @ y_train\n",
    "\n",
    "intercept = coefficients[0]\n",
    "slope = coefficients[1:]\n",
    "\n",
    "print(\"Intercept:\", intercept)\n",
    "print(\"Slope:\", slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = coefficients.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_with_intercept = np.hstack((np.ones((X_test.shape[0], 1)), X_test))\n",
    "\n",
    "y_pred = coefficients @ X_test_with_intercept.T\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test - y_pred.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Train SVR model\n",
    "svr = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = svr.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "y_test = y_test.squeeze()\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"RÂ² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.inverse_transform(np.expand_dims(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.inverse_transform(np.expand_dims(y_test, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.9\n",
    "vdi_scores = (model_df.loc[:, cols] > THRESHOLD).sum(axis=1)\n",
    "model_df['VDI_score'] = vdi_scores\n",
    "print(model_df[['company', 'year', 'VDI_score']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
